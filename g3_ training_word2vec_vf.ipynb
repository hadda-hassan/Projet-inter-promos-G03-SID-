{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"g3_ training_word2vec_vf.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"Rllxy5d89RqQ"},"source":["Created on Wednesday 13 January 2021  \n","\n","**Group 3 - Representation**  \n","**The objective of this notebook is to train a word2vec model with our corpus** \n","\n","@authors : Jules Boutibou"]},{"cell_type":"markdown","metadata":{"id":"2bHfozw-9Rqb"},"source":["---"]},{"cell_type":"markdown","metadata":{"id":"blKzqPjs5J56"},"source":["# Libraries"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"w9aZF5nb2GJ9","executionInfo":{"elapsed":3368,"status":"ok","timestamp":1610705435357,"user":{"displayName":"Jules Boutibou","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggyc5dNDCMFVo6HX5idpNboNRlAei1MSIztxX79Yg=s64","userId":"04206329469966522988"},"user_tz":-60},"outputId":"397937f5-2671-4768-bf7c-f6d31a9b695b"},"source":["from tqdm import tqdm\n","from gensim.models import Word2Vec\n","from nltk.corpus import stopwords\n","import numpy as np\n","import pandas as pd\n","import os\n","import re\n","import time\n","import nltk\n","import unicodedata\n","nltk.download('stopwords')\n","tqdm.pandas()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"adOIeTTV4mwp"},"source":["# Importing and cleaning data"]},{"cell_type":"code","metadata":{"id":"d5KYTkUU4mZk"},"source":["# Import dataframe without duplicates\n","data = pd.read_json(\n","    '/content/drive/MyDrive/PIP 2021/Données/Deduplicated/df_concat_G1_G2_v0.json')\n","\n","# Keep only id and content of articles\n","data = data[[\"art_id\", \"art_content\", \"art_title\"]]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0AGGBiYZ9Rqm"},"source":["# Preprocessing"]},{"cell_type":"code","metadata":{"id":"q-HVYBZh3o3Y"},"source":["def preprocessing(sentences) -> list:\n","    \"\"\"\n","    Takes a column containing sentences, and return the processed text.\n","    Removes punctuation, stopwords, numbers, accents, white spaces, and lemmatize a text\n","    \"\"\"\n","\n","    processed_sentences = []\n","\n","    for sentence in tqdm(sentences):\n","\n","        # Convert to lowercase\n","        sentence = sentence.lower()\n","\n","        # Remove space(begin, end)\n","        sentence = str(sentence).strip()\n","\n","        # Remove white space\n","        sentence = str(sentence).strip()\n","\n","        # Remove accent\n","        sentence = ''.join((c for c in unicodedata.normalize(\n","            'NFD', sentence) if unicodedata.category(c) != 'Mn'))\n","\n","        # Remove number\n","        sentence = ''.join([i for i in sentence if not i.isdigit()])\n","\n","        # Remove other non-alphabets symbols with space (i.e. keep only alphabets, whitespaces and char ')\n","        sentence = re.sub(\"[^a-zA-Z ']\", '', sentence)\n","\n","        words = sentence.split()\n","\n","        # Keep word after ' char\n","        # i.e. l'accord --> keeps accord instead of laccord\n","        sentence = [w.split(\"'\")[1] if \"'\" in w else w for w in words]\n","\n","        # Keep words that have length of more than 2, remove those with length 1 or 2\n","        processed_sentences.append(\n","            ' '.join([w for w in sentence if len(w) > 2 or len(w) < 50]))\n","\n","    return processed_sentences"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dZ0JkG3n5DXJ","executionInfo":{"elapsed":31028,"status":"ok","timestamp":1610705463074,"user":{"displayName":"Jules Boutibou","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggyc5dNDCMFVo6HX5idpNboNRlAei1MSIztxX79Yg=s64","userId":"04206329469966522988"},"user_tz":-60},"outputId":"0aa877ff-d905-4d4c-f264-a85b2a4e1462"},"source":["# Import french stopwords\n","stop = stopwords.words('french')\n","\n","# Cleaning content column\n","data['art_content_clean'] = preprocessing(data['art_content'])\n","data['art_content_clean'] = data['art_content_clean'].apply(\n","    lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n","\n","# Cleaning title column\n","data['art_title_clean'] = preprocessing(data['art_title'])\n","data['art_title_clean'] = data['art_title_clean'].apply(\n","    lambda x: ' '.join([word for word in x.split() if word not in (stop)]))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["100%|██████████| 7544/7544 [00:16<00:00, 467.68it/s]\n","100%|██████████| 7544/7544 [00:00<00:00, 23901.01it/s]\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"6BJCMHf89Rqo"},"source":["# Model training"]},{"cell_type":"markdown","metadata":{"id":"FFrStNAQ9Rqo"},"source":["### Concatenation of art_content and art_title to train the model"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"O2Gu3n47F55M","executionInfo":{"elapsed":31876,"status":"ok","timestamp":1610705463930,"user":{"displayName":"Jules Boutibou","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggyc5dNDCMFVo6HX5idpNboNRlAei1MSIztxX79Yg=s64","userId":"04206329469966522988"},"user_tz":-60},"outputId":"373cbc9c-721a-4c91-8dc1-2160627fa0fb"},"source":["sentences_content = list(\n","    data['art_content_clean'].progress_apply(str.split).values)\n","sentences_title = list(\n","    data['art_title_clean'].progress_apply(str.split).values)\n","train_sentences = [*sentences_content, *sentences_title]"],"execution_count":null,"outputs":[{"output_type":"stream","text":["100%|██████████| 7544/7544 [00:00<00:00, 16430.04it/s]\n","100%|██████████| 7544/7544 [00:00<00:00, 37602.10it/s]\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"IZyvsNkg9Rqp"},"source":["### Model training"]},{"cell_type":"code","metadata":{"id":"IIDoPD4I4Opa"},"source":["# Training the word2vec skip-gram model\n","model = Word2Vec(sentences=train_sentences,\n","                 sg=1,  # sg = 1 --> skip-gram model\n","                 size=500,\n","                 workers=4,\n","                 window=5)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"abVK_uafGbSu"},"source":["# Saving the model\n","model.wv.save_word2vec_format(\n","    '/content/drive/MyDrive/PIP 2021/Word Embedding/Modele/Pretrained_model/model_trained_on_articles.txt')"],"execution_count":null,"outputs":[]}]}