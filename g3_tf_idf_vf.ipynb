{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"g3_tf_idf_vf.ipynb","provenance":[],"collapsed_sections":["-fKBLVArCxwS","-OrCJM_4T1wI","QGl3ZZdSUNFG","zeZw433UXVq8","uOChtYedX-R_","5MLqRkgdYE9i","TvJkzLxVYbcW","pNe0FHsfY8CQ","mrf72BEJZFwU","B7OxHpVsZTe8","spcT_SoWZglH","mtg791OpaFxg"]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"3kaYa-kz9w0s"},"source":["Created on Monday 11 January 2021  \n","\n","**Group 3 - Representation**  \n","**The objective of this notebook is to create 1-gram and 2-gram TFIDF representation** \n","\n","@authors : Fatima Seck, Jingmeng Yang, Sacha Di Rienzo"]},{"cell_type":"markdown","metadata":{"id":"STJ9O_G69w0v"},"source":["---"]},{"cell_type":"code","metadata":{"id":"2XYBkDpv9w0x"},"source":["!pip install git+https://github.com/ClaudeCoulombe/FrenchLefffLemmatizer.git\n","!python -m spacy download fr_core_news_sm\n","!python -m spacy download fr\n","!pip install spacy_lefff"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-fKBLVArCxwS"},"source":["# Import libraries"]},{"cell_type":"code","metadata":{"id":"HcgFMRf9Xlbg"},"source":["import pandas as pd\n","import pickle\n","import unicodedata\n","from string import punctuation\n","from scipy.spatial import distance\n","from french_lefff_lemmatizer.french_lefff_lemmatizer import FrenchLefffLemmatizer\n","import warnings \n","import spacy\n","from spacy_lefff import LefffLemmatizer, POSTagger\n","from itertools import combinations \n","from tqdm import tqdm \n","from collections import Counter\n","\n","#nltk\n","import nltk\n","from nltk.tokenize import word_tokenize\n","from nltk.corpus import stopwords,words\n","nltk.download('stopwords')\n","nltk.download('punkt')\n","nltk.download('words')\n","\n","#sklearn\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.feature_extraction.text import TfidfVectorizer"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PaAIS7BH9w0y"},"source":["warnings.filterwarnings('ignore')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Il_wUEPKTtmu"},"source":["# I Data Import and cleaning"]},{"cell_type":"markdown","metadata":{"id":"-OrCJM_4T1wI"},"source":["## I.1 import and clean data with lem"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VeUxdEyOXoT3","executionInfo":{"elapsed":545,"status":"ok","timestamp":1610638148442,"user":{"displayName":"Jingmeng YANG","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgwV8M7lqWKkakDkxRRbTqU-yAO1mttwhGfXuMr=s64","userId":"07064816488509152295"},"user_tz":-60},"outputId":"85e19da8-378e-4b77-8137-a6d7c5762a5d"},"source":["cd /content/drive/MyDrive/Colab Notebooks/"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/drive/MyDrive/Colab Notebooks\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":419},"id":"uHVgxj3rUCR0","executionInfo":{"elapsed":2048,"status":"ok","timestamp":1610638185470,"user":{"displayName":"Jingmeng YANG","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgwV8M7lqWKkakDkxRRbTqU-yAO1mttwhGfXuMr=s64","userId":"07064816488509152295"},"user_tz":-60},"outputId":"ca979e61-7a87-418e-d0cb-f1d25a1f52dd"},"source":["# Import dataset\n","df_1 = pd.read_json('df_deduplicated_v4.json')\n","df_2 = pd.read_json('df_final_clean_with_lem_v0.json')\n","# Merge DataFrame\n","df_with_lem = df_1.merge(df_2, how = 'left', left_on = 'art_id', right_on = 'art_id')\n","# Keep columns : art_id, art_content_x and art_content_clean_with_lem\n","df_with_lem = df_with_lem[['art_id', 'art_content_x', 'art_content_clean_with_lem']]\n","df_with_lem = df_with_lem.rename(columns = {'art_content_x': 'art_content'})\n","df_with_lem['art_id'] = df_with_lem['art_id'].astype(int)\n","# Drop missing values in art content column\n","df_with_lem =  df_with_lem.dropna(subset = ['art_content_clean_with_lem'])\n","# Index has to match with the dropped rows -> reset_index\n","df_with_lem = df_with_lem.reset_index(drop = True)\n","df_with_lem"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>art_id</th>\n","      <th>art_content</th>\n","      <th>art_content_clean_with_lem</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>La FNCDG et l’ANDCDG ont publié en septembre l...</td>\n","      <td>fncdg andcdg publier septembre eme edition pa...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>Malgré la levée des mesures de confinement le ...</td>\n","      <td>malgre levee mesure confinement mai plupart m...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>25</td>\n","      <td>Quels étaient les objectifs poursuivis par le ...</td>\n","      <td>quels etaient objectif poursuivre gouvernemen...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>27</td>\n","      <td>La journée thématique, qui aura lieu durant le...</td>\n","      <td>journee thematique lieu durant salon preventi...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>28</td>\n","      <td>La 1ère journée thématique en région sur le th...</td>\n","      <td>ere journee thematique region theme ver nouve...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>7476</th>\n","      <td>12256</td>\n","      <td>01/10/2020 - 18:20 Ouverture le 2 octobre 2020...</td>\n","      <td>ouverture octobre offre public achat volontai...</td>\n","    </tr>\n","    <tr>\n","      <th>7477</th>\n","      <td>12257</td>\n","      <td>MEDICREA : Ouverture de l'offre publique d'ach...</td>\n","      <td>medicrea ouverture offrir public achat volont...</td>\n","    </tr>\n","    <tr>\n","      <th>7478</th>\n","      <td>12258</td>\n","      <td>© Fournis par La Tribune 14 startups différent...</td>\n","      <td>fournir tribune startups differentes reussi m...</td>\n","    </tr>\n","    <tr>\n","      <th>7479</th>\n","      <td>12259</td>\n","      <td>Ce communiqué ne constitue pas une offre d'acq...</td>\n","      <td>communique constituer offrir acquerir titre c...</td>\n","    </tr>\n","    <tr>\n","      <th>7480</th>\n","      <td>12260</td>\n","      <td>Ouverture le 2 octobre 2020 de l'offre publiqu...</td>\n","      <td>ouverture octobre offre public achat volontai...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>7481 rows × 3 columns</p>\n","</div>"],"text/plain":["      art_id  ...                         art_content_clean_with_lem\n","0          1  ...   fncdg andcdg publier septembre eme edition pa...\n","1          2  ...   malgre levee mesure confinement mai plupart m...\n","2         25  ...   quels etaient objectif poursuivre gouvernemen...\n","3         27  ...   journee thematique lieu durant salon preventi...\n","4         28  ...   ere journee thematique region theme ver nouve...\n","...      ...  ...                                                ...\n","7476   12256  ...   ouverture octobre offre public achat volontai...\n","7477   12257  ...   medicrea ouverture offrir public achat volont...\n","7478   12258  ...   fournir tribune startups differentes reussi m...\n","7479   12259  ...   communique constituer offrir acquerir titre c...\n","7480   12260  ...   ouverture octobre offre public achat volontai...\n","\n","[7481 rows x 3 columns]"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"markdown","metadata":{"id":"QGl3ZZdSUNFG"},"source":["## I.2 Data import and cleaning"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":491},"id":"t1QzO21uUPkq","executionInfo":{"elapsed":88385,"status":"ok","timestamp":1610638288571,"user":{"displayName":"Jingmeng YANG","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgwV8M7lqWKkakDkxRRbTqU-yAO1mttwhGfXuMr=s64","userId":"07064816488509152295"},"user_tz":-60},"outputId":"a7f1cda8-7905-4589-c503-4f8ad7f84d82"},"source":["# Import dataset\n","df_deduplicated = pd.read_json('df_deduplicated_v4.json')\n","df_deduplicated = df_deduplicated[['art_id', 'art_title']]\n","\n","# Spacy lemmatization\n","nlp = spacy.load('fr')\n","french_lemmatizer = LefffLemmatizer()\n","nlp.add_pipe(french_lemmatizer, name='lefff')\n","\n","\n","# Lemmatization function\n","def lemmatize_spacy(text: str) -> str:\n","    \"\"\"Documentation\n","\n","    Parameters:\n","     text: text to lemmatize\n","\n","    Out:\n","     new_text: the same text after lemmatization\n","\n","    \"\"\"\n","    text = nlp(text)\n","    new_text = \"\"\n","    for word in text:\n","        new_word = word._.lefff_lemma if word._.lefff_lemma else word\n","        new_text = new_text+\" \"+str(new_word)\n","    return new_text\n","\n","\n","stop = stopwords.words('french')\n","punctuations = punctuation + \"’”“‘…„—᾿‐–‑′•›‹⁄―‚→（）『』》《。↓↵'͞ʻʿ'\"+'″￼'\n","\n","\n","def preprocess_text(sen: str) -> str:\n","    \"\"\"Documentation\n","\n","    Parameters:\n","      sen: sentence to preprocess\n","\n","    Out:\n","      out: the same sentence after deleting spaces, punctuations...\n","\n","    \"\"\"\n","    # Convert to lowercase\n","    sentence = sen.lower()\n","    # Remove space(begin, end)\n","    sentence = str(sentence).strip()\n","    # Remove white space\n","    sentence = str(sentence).strip()\n","\n","    # Remove punctuation\n","    for p in punctuations:\n","        sentence = sentence.replace(p, \" \")\n","    # Remove accent\n","    sentence = ''.join((c for c in unicodedata.normalize(\n","        'NFD', sentence) if unicodedata.category(c) != 'Mn'))\n","\n","    # Remove number\n","    sentence = ''.join([i for i in sentence if not i.isdigit()])\n","\n","    # Remove words which len are <2 or >50\n","    sentence = ' '.join([w for w in sentence.split() if len(w) > 1])\n","    sentence = ' '.join([w for w in sentence.split() if len(w) < 50])\n","    return sentence\n","\n","\n","# Apply functions\n","df_deduplicated['art_title_prepd'] = df_deduplicated['art_title'].apply(\n","    preprocess_text)\n","df_deduplicated['art_title_prepd'] = df_deduplicated['art_title_prepd'].apply(\n","    lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n","df_deduplicated[\"art_title_prepd\"] = tqdm(\n","    df_deduplicated[\"art_title_prepd\"].apply(lemmatize_spacy))\n","df_deduplicated"],"execution_count":null,"outputs":[{"output_type":"stream","text":["2021-01-14 15:30:14,386 - spacy_lefff.lefff - INFO - New LefffLemmatizer instantiated.\n","2021-01-14 15:30:14,388 - spacy_lefff.lefff - INFO - Reading lefff data...\n","2021-01-14 15:30:15,003 - spacy_lefff.lefff - INFO - Successfully loaded lefff lemmatizer\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 7490/7490 [00:00<00:00, 969011.01it/s]\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>art_id</th>\n","      <th>art_title</th>\n","      <th>art_title_prepd</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>9ème édition du Panorama de l’emploi territorial</td>\n","      <td>eme edition panorama emploi territorial</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>ACTUALITÉS FNCDG / COVID19</td>\n","      <td>actualites fncdg covid</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>25</td>\n","      <td>Interview de M. Olivier DUSSOPT, Secretaire d’...</td>\n","      <td>interview olivier dussopt secretaire etat aup...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>27</td>\n","      <td>Journée Thématique FNCDG « Les services de san...</td>\n","      <td>journee thematique fncdg service sante securi...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>28</td>\n","      <td>Journée Thématique FNCDG « Vers de nouveaux mo...</td>\n","      <td>journee thematique fncdg vers nouveau modes g...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>7485</th>\n","      <td>12256</td>\n","      <td>MEDICREA</td>\n","      <td>medicrea</td>\n","    </tr>\n","    <tr>\n","      <th>7486</th>\n","      <td>12257</td>\n","      <td>La bourse en ligne : MEDICREA : Ouverture de l...</td>\n","      <td>bourse ligne medicrea ouverture offrir public...</td>\n","    </tr>\n","    <tr>\n","      <th>7487</th>\n","      <td>12258</td>\n","      <td>Ÿnsect, Mirakl, Sendinblue, ManoMano, Doctolib...</td>\n","      <td>ynsect mirakl sendinblue manomano doctolib to...</td>\n","    </tr>\n","    <tr>\n","      <th>7488</th>\n","      <td>12259</td>\n","      <td>Medicrea International : Mise à disposition No...</td>\n","      <td>medicrea international mise disposition note ...</td>\n","    </tr>\n","    <tr>\n","      <th>7489</th>\n","      <td>12260</td>\n","      <td>Medicrea International : Ouverture de l'offre ...</td>\n","      <td>medicrea international ouverture offrir publi...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>7490 rows × 3 columns</p>\n","</div>"],"text/plain":["      art_id  ...                                    art_title_prepd\n","0          1  ...            eme edition panorama emploi territorial\n","1          2  ...                             actualites fncdg covid\n","2         25  ...   interview olivier dussopt secretaire etat aup...\n","3         27  ...   journee thematique fncdg service sante securi...\n","4         28  ...   journee thematique fncdg vers nouveau modes g...\n","...      ...  ...                                                ...\n","7485   12256  ...                                           medicrea\n","7486   12257  ...   bourse ligne medicrea ouverture offrir public...\n","7487   12258  ...   ynsect mirakl sendinblue manomano doctolib to...\n","7488   12259  ...   medicrea international mise disposition note ...\n","7489   12260  ...   medicrea international ouverture offrir publi...\n","\n","[7490 rows x 3 columns]"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"markdown","metadata":{"id":"zeZw433UXVq8"},"source":["## I.3 Data cleaned and stemmed import"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":419},"id":"A_wKnAt1XYwS","executionInfo":{"elapsed":1493,"status":"ok","timestamp":1610638631015,"user":{"displayName":"Jingmeng YANG","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgwV8M7lqWKkakDkxRRbTqU-yAO1mttwhGfXuMr=s64","userId":"07064816488509152295"},"user_tz":-60},"outputId":"d252f7fd-38cf-44bd-ccb2-ebcba5027a26"},"source":["# Import dataset\n","df_concat = pd.read_json(\"df_concat_G1_G2_v0_clean_V0.json\")\n","# Keep columns : art_id and art_content_clean_with_stem\n","df_concat = df_concat[['art_id', 'art_content_clean_with_stem']]\n","df_concat"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>art_id</th>\n","      <th>art_content_clean_with_stem</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>fncdg andcdg publ septembr eme edit panoram em...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>malgr leve mesur confin mai plupart mesur sani...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>25</td>\n","      <td>quel etaient object poursuiv gouvern cadr cet ...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>27</td>\n","      <td>journe themat lieu dur salon preventic them se...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>28</td>\n","      <td>ere journe themat region them ver nouveau mod ...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>7539</th>\n","      <td>G2_usine-digitale_462</td>\n","      <td>etre sur vill futur besoin infrastructur resil...</td>\n","    </tr>\n","    <tr>\n","      <th>7540</th>\n","      <td>G2_usine-digitale_517</td>\n","      <td>necessair pris conscienc vill enjeux cybersecu...</td>\n","    </tr>\n","    <tr>\n","      <th>7541</th>\n","      <td>G2_usine-digitale_696</td>\n","      <td>etre sur vill futur besoin infrastructur resil...</td>\n","    </tr>\n","    <tr>\n","      <th>7542</th>\n","      <td>G2_usine-digitale_785</td>\n","      <td>comment nouvel mobilit vont facon vill futur c...</td>\n","    </tr>\n","    <tr>\n","      <th>7543</th>\n","      <td>G2_usine-digitale_1507</td>\n","      <td>necessair pris conscienc vill enjeux cybersecu...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>7544 rows × 2 columns</p>\n","</div>"],"text/plain":["                      art_id                        art_content_clean_with_stem\n","0                          1  fncdg andcdg publ septembr eme edit panoram em...\n","1                          2  malgr leve mesur confin mai plupart mesur sani...\n","2                         25  quel etaient object poursuiv gouvern cadr cet ...\n","3                         27  journe themat lieu dur salon preventic them se...\n","4                         28  ere journe themat region them ver nouveau mod ...\n","...                      ...                                                ...\n","7539   G2_usine-digitale_462  etre sur vill futur besoin infrastructur resil...\n","7540   G2_usine-digitale_517  necessair pris conscienc vill enjeux cybersecu...\n","7541   G2_usine-digitale_696  etre sur vill futur besoin infrastructur resil...\n","7542   G2_usine-digitale_785  comment nouvel mobilit vont facon vill futur c...\n","7543  G2_usine-digitale_1507  necessair pris conscienc vill enjeux cybersecu...\n","\n","[7544 rows x 2 columns]"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"markdown","metadata":{"id":"kGCKFxjak9an"},"source":["# II 1-GRAM TF-IDF"]},{"cell_type":"markdown","metadata":{"id":"uOChtYedX-R_"},"source":["## II.1 Lemmatized data"]},{"cell_type":"code","metadata":{"id":"pAfg4YCte0YR"},"source":["vectorizer_1g = TfidfVectorizer(max_features = 1500, use_idf = True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":419},"id":"vPbPTLJuZnHy","executionInfo":{"elapsed":4309,"status":"ok","timestamp":1610638679813,"user":{"displayName":"Jingmeng YANG","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgwV8M7lqWKkakDkxRRbTqU-yAO1mttwhGfXuMr=s64","userId":"07064816488509152295"},"user_tz":-60},"outputId":"c64559e8-d2f6-404f-8a82-3a8e6c197d21"},"source":["# Create TF-IDF matrix and keep top 1500 max_features ordered by term frequency \n","vect_tf_with_lem_1g = vectorizer_1g.fit_transform(df_with_lem['art_content_clean_with_lem'])\n","tf_idf_1 = pd.DataFrame(vect_tf_with_lem_1g.toarray(), columns = vectorizer.get_feature_names())\n","# Turn data into the form of list\n","tf_idf_1['tf_idf_1_gram'] = tf_idf_1.values.tolist()\n","tf_idf_1 = tf_idf_1.filter(['tf_idf_1_gram'])\n","# Merge DataFrames\n","df_with_lem_tf_idf_1 = pd.merge(df_with_lem, tf_idf_1,  left_index = True, right_index = True)\n","# Keep columns: art_id and tf_idf_1_gram\n","df_with_lem_tf_idf_1 = df_with_lem_tf_idf_1[['art_id', 'tf_idf_1_gram']]\n","df_with_lem_tf_idf_1 = df_with_lem_tf_idf_1.reset_index(drop = True)\n","df_with_lem_tf_idf_1"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>art_id</th>\n","      <th>tf_idf_1_gram</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>25</td>\n","      <td>[0.0, 0.03073946656325203, 0.0, 0.0, 0.0, 0.0,...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>27</td>\n","      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>28</td>\n","      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>7476</th>\n","      <td>12256</td>\n","      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.037...</td>\n","    </tr>\n","    <tr>\n","      <th>7477</th>\n","      <td>12257</td>\n","      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.035...</td>\n","    </tr>\n","    <tr>\n","      <th>7478</th>\n","      <td>12258</td>\n","      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.031461122156988694...</td>\n","    </tr>\n","    <tr>\n","      <th>7479</th>\n","      <td>12259</td>\n","      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n","    </tr>\n","    <tr>\n","      <th>7480</th>\n","      <td>12260</td>\n","      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.035...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>7481 rows × 2 columns</p>\n","</div>"],"text/plain":["      art_id                                      tf_idf_1_gram\n","0          1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n","1          2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n","2         25  [0.0, 0.03073946656325203, 0.0, 0.0, 0.0, 0.0,...\n","3         27  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n","4         28  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n","...      ...                                                ...\n","7476   12256  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.037...\n","7477   12257  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.035...\n","7478   12258  [0.0, 0.0, 0.0, 0.0, 0.0, 0.031461122156988694...\n","7479   12259  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n","7480   12260  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.035...\n","\n","[7481 rows x 2 columns]"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"markdown","metadata":{"id":"5MLqRkgdYE9i"},"source":["## II.2 Title Data"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":419},"id":"bPAUkWUrYNJ8","executionInfo":{"elapsed":1408,"status":"ok","timestamp":1610638720046,"user":{"displayName":"Jingmeng YANG","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgwV8M7lqWKkakDkxRRbTqU-yAO1mttwhGfXuMr=s64","userId":"07064816488509152295"},"user_tz":-60},"outputId":"85ce095c-ff57-4430-cb0a-2e1b09f18122"},"source":["# Create TF-IDF matrix and keep top 1500 max_features ordered by term frequency \n","vect_title_1g = vectorizer_1g.fit_transform(df_deduplicated['art_title_prepd'])\n","tf_idf_1_gram_title = pd.DataFrame(vect_title_1g.toarray(), columns = vectorizer.get_feature_names(), index = df_deduplicated.index)\n","# Turn data into the form of list\n","tf_idf_1_gram_title['tf_idf_title_1_gram']= tf_idf_1_gram_title.values.tolist()\n","tf_idf_1_gram_title = tf_idf_1_gram_title.filter(['tf_idf_title_1_gram'])\n","# Merge DataFrames\n","df_deduplicated_tf_idf_1g_title = pd.merge(df_deduplicated, tf_idf_1_gram_title,  left_index = True, right_index = True)\n","# Keep columns: art_id and tf_idf_title_1_gram\n","df_deduplicated_tf_idf_1g_title = df_deduplicated_tf_idf_1g_title[['art_id', 'tf_idf_title_1_gram']]\n","df_deduplicated_tf_idf_1g_title"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>art_id</th>\n","      <th>tf_idf_title_1_gram</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>25</td>\n","      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>27</td>\n","      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>28</td>\n","      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>7485</th>\n","      <td>12256</td>\n","      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n","    </tr>\n","    <tr>\n","      <th>7486</th>\n","      <td>12257</td>\n","      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n","    </tr>\n","    <tr>\n","      <th>7487</th>\n","      <td>12258</td>\n","      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n","    </tr>\n","    <tr>\n","      <th>7488</th>\n","      <td>12259</td>\n","      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n","    </tr>\n","    <tr>\n","      <th>7489</th>\n","      <td>12260</td>\n","      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>7490 rows × 2 columns</p>\n","</div>"],"text/plain":["      art_id                                tf_idf_title_1_gram\n","0          1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n","1          2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n","2         25  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n","3         27  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n","4         28  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n","...      ...                                                ...\n","7485   12256  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n","7486   12257  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n","7487   12258  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n","7488   12259  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n","7489   12260  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n","\n","[7490 rows x 2 columns]"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"markdown","metadata":{"id":"TvJkzLxVYbcW"},"source":["## II.3 Stemmed Data"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":419},"id":"oc4PhVGIYgqS","executionInfo":{"elapsed":4175,"status":"ok","timestamp":1610638744754,"user":{"displayName":"Jingmeng YANG","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgwV8M7lqWKkakDkxRRbTqU-yAO1mttwhGfXuMr=s64","userId":"07064816488509152295"},"user_tz":-60},"outputId":"0b0b453a-7276-4c59-c5f2-8ead3a3ff074"},"source":["# Create TF-IDF matrix and keep top 1500 max_features ordered by term frequency \n","vect_concat_1g = vectorizer_1g.fit_transform(df_concat['art_content_clean_with_stem'])\n","tf_idf_1_gram_concat = pd.DataFrame(vect_concat_1g.toarray(), columns = vectorizer.get_feature_names())\n","# Turn data into the form of list\n","tf_idf_1_gram_concat['tf_idf_1_gram'] = tf_idf_1_gram_concat.values.tolist()\n","tf_idf_1_gram_concat = tf_idf_1_gram_concat.filter(['tf_idf_1_gram'])\n","# Merge DataFrames\n","df_concat_tf_idf_1g = pd.merge(df_concat, tf_idf_1_gram_concat,  left_index = True, right_index = True)\n","# Keep columns: art_id and tf_idf_1_gram\n","df_concat_tf_idf_1g = df_concat_tf_idf_1g[['art_id', 'tf_idf_1_gram']]\n","df_concat_tf_idf_1g = df_concat_tf_idf_1g.reset_index(drop = True)\n","df_concat_tf_idf_1g"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>art_id</th>\n","      <th>tf_idf_1_gram</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>25</td>\n","      <td>[0.018063225702737783, 0.0, 0.0, 0.0, 0.0, 0.0...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>27</td>\n","      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>28</td>\n","      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>7539</th>\n","      <td>G2_usine-digitale_462</td>\n","      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n","    </tr>\n","    <tr>\n","      <th>7540</th>\n","      <td>G2_usine-digitale_517</td>\n","      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n","    </tr>\n","    <tr>\n","      <th>7541</th>\n","      <td>G2_usine-digitale_696</td>\n","      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n","    </tr>\n","    <tr>\n","      <th>7542</th>\n","      <td>G2_usine-digitale_785</td>\n","      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n","    </tr>\n","    <tr>\n","      <th>7543</th>\n","      <td>G2_usine-digitale_1507</td>\n","      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>7544 rows × 2 columns</p>\n","</div>"],"text/plain":["                      art_id                                      tf_idf_1_gram\n","0                          1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n","1                          2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n","2                         25  [0.018063225702737783, 0.0, 0.0, 0.0, 0.0, 0.0...\n","3                         27  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n","4                         28  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n","...                      ...                                                ...\n","7539   G2_usine-digitale_462  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n","7540   G2_usine-digitale_517  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n","7541   G2_usine-digitale_696  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n","7542   G2_usine-digitale_785  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n","7543  G2_usine-digitale_1507  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n","\n","[7544 rows x 2 columns]"]},"metadata":{"tags":[]},"execution_count":18}]},{"cell_type":"markdown","metadata":{"id":"rgKIih-eY3JA"},"source":["# III 2-GRAM TF-IDF "]},{"cell_type":"markdown","metadata":{"id":"pNe0FHsfY8CQ"},"source":["## III.1 Lemmatized Data"]},{"cell_type":"code","metadata":{"id":"CwdI-bEyggan"},"source":["vectorizer_2g = TfidfVectorizer(max_features = 1500, use_idf = True, ngram_range = (2, 2))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":419},"id":"djXM9K4ycpVg","executionInfo":{"elapsed":16685,"status":"ok","timestamp":1610638773993,"user":{"displayName":"Jingmeng YANG","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgwV8M7lqWKkakDkxRRbTqU-yAO1mttwhGfXuMr=s64","userId":"07064816488509152295"},"user_tz":-60},"outputId":"24f864dc-4b2f-4cb1-d112-125e17445caf"},"source":["# TF-IDF 2 gram -> ngram_range = (2, 2)\n","# 1500 max_features ordered by term frequency across the corpus.\n","vect_tf_with_lem_2g = vectorizer_2g.fit_transform(df_with_lem['art_content_clean_with_lem'])\n","tf_idf_2 = pd.DataFrame(vect_tf_with_lem_2g.toarray(), columns = vectorizer.get_feature_names())\n","# Turn data into the form of list\n","tf_idf_2['TF_IDF_2_gram']= tf_idf_2.values.tolist()\n","tf_idf_2 = tf_idf_2.filter(['TF_IDF_2_gram'])\n","# Merge DataFrames\n","df_with_lem_tf_idf_2 = pd.merge(tf_idf_2, df_with_lem, left_index = True, right_index = True)\n","# Keep columns: art_id and TF_IDF_2_gram\n","df_with_lem_tf_idf_2 = df_with_lem_tf_idf_2[['art_id','TF_IDF_2_gram']]\n","df_with_lem_tf_idf_2 = df_with_lem_tf_idf_2.reset_index(drop = True)\n","df_with_lem_tf_idf_2"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>art_id</th>\n","      <th>TF_IDF_2_gram</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>25</td>\n","      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>27</td>\n","      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>28</td>\n","      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>7476</th>\n","      <td>12256</td>\n","      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n","    </tr>\n","    <tr>\n","      <th>7477</th>\n","      <td>12257</td>\n","      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n","    </tr>\n","    <tr>\n","      <th>7478</th>\n","      <td>12258</td>\n","      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n","    </tr>\n","    <tr>\n","      <th>7479</th>\n","      <td>12259</td>\n","      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n","    </tr>\n","    <tr>\n","      <th>7480</th>\n","      <td>12260</td>\n","      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>7481 rows × 2 columns</p>\n","</div>"],"text/plain":["      art_id                                      TF_IDF_2_gram\n","0          1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n","1          2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n","2         25  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n","3         27  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n","4         28  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n","...      ...                                                ...\n","7476   12256  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n","7477   12257  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n","7478   12258  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n","7479   12259  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n","7480   12260  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n","\n","[7481 rows x 2 columns]"]},"metadata":{"tags":[]},"execution_count":20}]},{"cell_type":"markdown","metadata":{"id":"mrf72BEJZFwU"},"source":["## III.2 Title Data"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":419},"id":"Gj7YAwrqZHqd","executionInfo":{"elapsed":1636,"status":"ok","timestamp":1610638783349,"user":{"displayName":"Jingmeng YANG","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgwV8M7lqWKkakDkxRRbTqU-yAO1mttwhGfXuMr=s64","userId":"07064816488509152295"},"user_tz":-60},"outputId":"9d4de957-f2a9-401f-9123-61df031fb496"},"source":["# TF-IDF 2 gram -> ngram_range = (2, 2)\n","# 1500 max_features ordered by term frequency across the corpus.\n","vect_title_2g = vectorizer_2g.fit_transform(df_deduplicated['art_title_prepd'])\n","tf_idf_2_gram_title = pd.DataFrame(vect_title_2g.toarray(), columns = vectorizer.get_feature_names())\n","# Turn data into the form of list\n","tf_idf_2_gram_title['tf_idf_title_2_gram'] = tf_idf_2_gram_title.values.tolist()\n","tf_idf_2_gram_title = tf_idf_2_gram_title.filter(['tf_idf_title_2_gram'])\n","# Merge DataFrames\n","df_deduplicated_tf_idf_2g_title = pd.merge(df_deduplicated, tf_idf_2_gram_title,  left_index = True, right_index = True)\n","# Keep columns: art_id and tf_idf_title_2_gram\n","df_deduplicated_tf_idf_2g_title = df_deduplicated_tf_idf_2g_title[['art_id', 'tf_idf_title_2_gram']]\n","df_deduplicated_tf_idf_2g_title"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>art_id</th>\n","      <th>tf_idf_title_2_gram</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>25</td>\n","      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>27</td>\n","      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>28</td>\n","      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>7485</th>\n","      <td>12256</td>\n","      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n","    </tr>\n","    <tr>\n","      <th>7486</th>\n","      <td>12257</td>\n","      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n","    </tr>\n","    <tr>\n","      <th>7487</th>\n","      <td>12258</td>\n","      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n","    </tr>\n","    <tr>\n","      <th>7488</th>\n","      <td>12259</td>\n","      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n","    </tr>\n","    <tr>\n","      <th>7489</th>\n","      <td>12260</td>\n","      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>7490 rows × 2 columns</p>\n","</div>"],"text/plain":["      art_id                                tf_idf_title_2_gram\n","0          1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n","1          2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n","2         25  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n","3         27  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n","4         28  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n","...      ...                                                ...\n","7485   12256  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n","7486   12257  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n","7487   12258  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n","7488   12259  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n","7489   12260  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n","\n","[7490 rows x 2 columns]"]},"metadata":{"tags":[]},"execution_count":21}]},{"cell_type":"markdown","metadata":{"id":"B7OxHpVsZTe8"},"source":["## III.3 Stemmed Data"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":419},"id":"lOQWTCWwZWn3","executionInfo":{"elapsed":14685,"status":"ok","timestamp":1610638802761,"user":{"displayName":"Jingmeng YANG","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgwV8M7lqWKkakDkxRRbTqU-yAO1mttwhGfXuMr=s64","userId":"07064816488509152295"},"user_tz":-60},"outputId":"57b3ae8d-155c-4b4c-a4d3-8e397cbb62fb"},"source":["# TF-IDF 2 gram -> ngram_range = (2, 2)\n","# 1500 max_features ordered by term frequency across the corpus.\n","vect_concat_2g = vectorizer_2g.fit_transform(\n","    df_concat['art_content_clean_with_stem'])\n","tf_idf_2_gram_concat = pd.DataFrame(\n","    vect_concat_2g.toarray(), columns=vectorizer.get_feature_names())\n","# Turn data into the form of list\n","tf_idf_2_gram_concat['TF_IDF_2_gram'] = tf_idf_2_gram_concat.values.tolist()\n","tf_idf_2_gram_concat = tf_idf_2_gram_concat.filter(['TF_IDF_2_gram'])\n","# Merge DataFrames\n","df_concat_tf_idf_2g = pd.merge(\n","    df_concat, tf_idf_2_gram_concat,  left_index=True, right_index=True)\n","# Keep columns: art_id and TF_IDF_2_gram\n","df_concat_tf_idf_2g = df_concat_tf_idf_2g[['art_id', 'TF_IDF_2_gram']]\n","df_concat_tf_idf_2g = df_concat_tf_idf_2g.reset_index(drop=True)\n","df_concat_tf_idf_2g"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>art_id</th>\n","      <th>TF_IDF_2_gram</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>25</td>\n","      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>27</td>\n","      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>28</td>\n","      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>7539</th>\n","      <td>G2_usine-digitale_462</td>\n","      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n","    </tr>\n","    <tr>\n","      <th>7540</th>\n","      <td>G2_usine-digitale_517</td>\n","      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n","    </tr>\n","    <tr>\n","      <th>7541</th>\n","      <td>G2_usine-digitale_696</td>\n","      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n","    </tr>\n","    <tr>\n","      <th>7542</th>\n","      <td>G2_usine-digitale_785</td>\n","      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n","    </tr>\n","    <tr>\n","      <th>7543</th>\n","      <td>G2_usine-digitale_1507</td>\n","      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>7544 rows × 2 columns</p>\n","</div>"],"text/plain":["                      art_id                                      TF_IDF_2_gram\n","0                          1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n","1                          2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n","2                         25  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n","3                         27  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n","4                         28  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n","...                      ...                                                ...\n","7539   G2_usine-digitale_462  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n","7540   G2_usine-digitale_517  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n","7541   G2_usine-digitale_696  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n","7542   G2_usine-digitale_785  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n","7543  G2_usine-digitale_1507  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n","\n","[7544 rows x 2 columns]"]},"metadata":{"tags":[]},"execution_count":22}]},{"cell_type":"markdown","metadata":{"id":"0i0wUBGoZdvI"},"source":["# IV Export data"]},{"cell_type":"markdown","metadata":{"id":"spcT_SoWZglH"},"source":["## IV.1 1-GRAM TF-IDF models "]},{"cell_type":"code","metadata":{"id":"VH8mm-ZTZxUv"},"source":["df_with_lem_tf_idf_1.to_json(\n","    r'df_TF_IDF_1_GRAM_df_with_lem_vf.json', orient='records')\n","filename = 'model_Tf-Idf_1-gram_df_clean_with_lem_vf.sav'\n","pickle.dump(vect_tf_with_lem_1g, open(filename, 'wb'))\n","\n","df_deduplicated_tf_idf_1g_title.to_json(\n","    r'df_TF_IDF_TITLE_1_GRAM_vf.json', orient='records')\n","filename = 'model_Tf-Idf_1-gram_title_vf.sav'\n","pickle.dump(vect_title_1g, open(filename, 'wb'))\n","\n","df_concat_tf_idf_1g.to_json(\n","    r'df_TF_IDF_1_GRAM_df_concat_G1_G2_clean_stem_vf.json', orient='records')\n","filename = 'model_Tf-Idf_1-gram_df_concat_G1_G2_vf.sav'\n","pickle.dump(vect_concat_1g, open(filename, 'wb'))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mtg791OpaFxg"},"source":["## IV.2 2-GRAM TF-IDF models "]},{"cell_type":"code","metadata":{"id":"WcOzqrM7aHt-"},"source":["df_with_lem_tf_idf_2.to_json(\n","    r'df_TF_IDF_2_GRAM_df_with_lem_vf.json', orient='records')\n","filename = 'model_Tf-Idf_2-gram_df_clean_with_lem_vf.sav'\n","pickle.dump(vect_tf_with_lem_2g, open(filename, 'wb'))\n","\n","df_deduplicated_tf_idf_2g_title.to_json(\n","    r'df_TF_IDF_TITLE_2_GRAM_vf.json', orient='records')\n","filename = 'model_Tf-Idf_2-gram_title_vf.sav'\n","pickle.dump(vect_title_2g, open(filename, 'wb'))\n","\n","df_concat_tf_idf_2g.to_json(\n","    r'df_TF_IDF_2_GRAM_df_concat_G1_G2_clean_stem_vf.json', orient='records')\n","filename = 'model_Tf-Idf_2-gram_df_concat_G1_G2_vf.sav'\n","pickle.dump(vect_concat_2g, open(filename, 'wb'))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IMJrn4ad9w1K"},"source":["---"]}]}