{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"g3_fasttext_embedding_vf.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"RxsoEHBp9efF"},"source":["Created on Tuesday 12 January 2021  \n","\n","**Group 3 - Representation**  \n","**The objective of this notebook is to create a word embedding representation with FastText**\n","\n","@authors : Lingeshwari Ramlugon, Thibault Gallou"]},{"cell_type":"markdown","metadata":{"id":"skJ4ZdIm9efM"},"source":["---"]},{"cell_type":"markdown","metadata":{"id":"peWOlXCWCKZR"},"source":["# Word Embedding with FastText - non lemmatized"]},{"cell_type":"markdown","metadata":{"id":"3uod_rrTCyad"},"source":["## Import Libraires"]},{"cell_type":"code","metadata":{"id":"B-uU3-AUCAZy"},"source":["from string import punctuation\n","from operator import itemgetter\n","import pandas as pd\n","import numpy as np\n","import unicodedata\n","import re\n","\n","# sklearn\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.metrics.pairwise import cosine_similarity\n","\n","# gensim\n","import gensim\n","from gensim.models.keyedvectors import KeyedVectors\n","from gensim.models import Word2Vec\n","\n","# nltk\n","import nltk\n","from nltk.corpus import stopwords\n","nltk.download('punkt')\n","nltk.download('stopwords')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-rYyentdu1Lw"},"source":["## Mount the drive"]},{"cell_type":"code","metadata":{"id":"cuVeU3qWtfyG"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nMby4Fznu7Rl"},"source":["## FastText implementation"]},{"cell_type":"markdown","metadata":{"id":"KnCwUnUaT0Tt"},"source":["Pretrained model in the french section: https://fasttext.cc/docs/en/crawl-vectors.html"]},{"cell_type":"code","metadata":{"id":"Owttc08ICSkH"},"source":["# Loading the FastText model pretrained on french data\n","model = KeyedVectors.load_word2vec_format(\n","    '/content/drive/MyDrive/PIP 2021/Word Embedding/Modele/cc.fr.300.txt', binary=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"h9U1nfn6RLyo"},"source":["print(model.vocab)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IEmWpKE4vCmm"},"source":["## Cleaning vocabulary"]},{"cell_type":"code","metadata":{"id":"srXpa5SwUfBK"},"source":["def strip_accents(s: str) -> str:\n","    \"\"\" Documentation\n","    Returns the vocabulary without accent\n","    \"\"\"\n","\n","    return ''.join(c for c in unicodedata.normalize('NFD', s) if unicodedata.category(c) != 'Mn')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hOavLJb5UfBM"},"source":["# Remove the pos tag to only keep the french word, and convert to lowercase\n","model.vocab = {strip_accents(\n","    k.split('_')[0].lower()): v for k, v in model.vocab.items()}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8lSc9QqYUfBN"},"source":["# Import of the french stopwords\n","stop = stopwords.words('french')\n","vocab = list(model.vocab.keys())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bCaVE9L6UfBO"},"source":["# Vocabulary words contain no punctuation, no french stopword and have more than 2 characters\n","vocab = [v for v in vocab if v not in stop and v.isalpha() and len(v) > 2]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0sffAQ4zUfBQ"},"source":["# New cleaned vocabulary\n","model.vocab = dict(zip(vocab, itemgetter(*vocab)(model.vocab)))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7WVs94IfWa57"},"source":["model.vocab"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7zZ_AgkNRi57"},"source":["## Import deduplicated data"]},{"cell_type":"code","metadata":{"id":"grwhmVWhyP8i"},"source":["# Import the cleaned data, without lemmatization\n","data = pd.read_json(\n","    '/content/drive/MyDrive/PIP 2021/Données/Deduplicated/df_concat_G1_G2_v0.json')\n","data.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":202},"id":"VM0SzOQeGSuW","executionInfo":{"elapsed":520,"status":"ok","timestamp":1610624116154,"user":{"displayName":"Ling","photoUrl":"","userId":"05619430897057846277"},"user_tz":-60},"outputId":"dd86abcf-4432-4696-9cdb-d74a58b7e252"},"source":["# Keep only id and title of articles\n","data = data[[\"art_id\",\"art_content\"]]\n","data.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>art_id</th>\n","      <th>art_content</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>La FNCDG et l’ANDCDG ont publié en septembre l...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>Malgré la levée des mesures de confinement le ...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>25</td>\n","      <td>Quels étaient les objectifs poursuivis par le ...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>27</td>\n","      <td>La journée thématique, qui aura lieu durant le...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>28</td>\n","      <td>La 1ère journée thématique en région sur le th...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  art_id                                        art_content\n","0      1  La FNCDG et l’ANDCDG ont publié en septembre l...\n","1      2  Malgré la levée des mesures de confinement le ...\n","2     25  Quels étaient les objectifs poursuivis par le ...\n","3     27  La journée thématique, qui aura lieu durant le...\n","4     28  La 1ère journée thématique en région sur le th..."]},"metadata":{"tags":[]},"execution_count":18}]},{"cell_type":"code","metadata":{"id":"cgzLoKEudXLD"},"source":["# Create function to clean articles\n","stop = stopwords.words('french')\n","punctuations = punctuation+\"’”“‘…„—᾿‐–‑′•›‹⁄―‚→（）『』》《。↓↵'͞ʻʿ'\"+'″￼'\n","\n","\n","def preprocess_text(sen: str) -> str:\n","    \"\"\" Documentation \n","    Removes punctuation, stopwords, numbers, accents, white spaces, and lemmatize a text\n","    \"\"\"\n","\n","    # Convert to lowercase\n","    sentence = sen.lower()\n","    # Remove space(begin, end)\n","    sentence = str(sentence).strip()\n","    # Remove white space\n","    sentence = str(sentence).strip()\n","\n","    # Remove punctuation\n","    for p in punctuations:\n","        sentence = sentence.replace(p, \" \")\n","\n","    # Remove accent\n","    sentence = ''.join((c for c in unicodedata.normalize(\n","        'NFD', sentence) if unicodedata.category(c) != 'Mn'))\n","\n","    # Remove number\n","    sentence = ''.join([i for i in sentence if not i.isdigit()])\n","\n","    # Remove words which len are <2 or >50\n","    sentence = ' '.join([w for w in sentence.split() if len(w) > 1])\n","    sentence = ' '.join([w for w in sentence.split() if len(w) < 50])\n","\n","    return sentence"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"io8ptfrSdaIn"},"source":["# Clean elements of column 'art_content'\n","# Create new column 'art_content_clean'\n","data['art_content_clean'] = data['art_content'].apply(preprocess_text)\n","data['art_content_clean'] = data['art_content_clean'].apply(\n","    lambda x: ' '.join([word for word in x.split() if word not in (stop)]))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":202},"id":"_69ulCkzZ6zd","executionInfo":{"elapsed":837,"status":"ok","timestamp":1610624166847,"user":{"displayName":"Ling","photoUrl":"","userId":"05619430897057846277"},"user_tz":-60},"outputId":"6833414e-2b95-4698-8e3e-d2549a5c7563"},"source":["data.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>art_id</th>\n","      <th>art_content</th>\n","      <th>art_content_clean</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>La FNCDG et l’ANDCDG ont publié en septembre l...</td>\n","      <td>fncdg andcdg publie septembre eme edition pano...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>Malgré la levée des mesures de confinement le ...</td>\n","      <td>malgre levee mesures confinement mai plupart m...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>25</td>\n","      <td>Quels étaient les objectifs poursuivis par le ...</td>\n","      <td>quels etaient objectifs poursuivis gouvernemen...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>27</td>\n","      <td>La journée thématique, qui aura lieu durant le...</td>\n","      <td>journee thematique lieu durant salon preventic...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>28</td>\n","      <td>La 1ère journée thématique en région sur le th...</td>\n","      <td>ere journee thematique region theme vers nouve...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  art_id  ...                                  art_content_clean\n","0      1  ...  fncdg andcdg publie septembre eme edition pano...\n","1      2  ...  malgre levee mesures confinement mai plupart m...\n","2     25  ...  quels etaient objectifs poursuivis gouvernemen...\n","3     27  ...  journee thematique lieu durant salon preventic...\n","4     28  ...  ere journee thematique region theme vers nouve...\n","\n","[5 rows x 3 columns]"]},"metadata":{"tags":[]},"execution_count":21}]},{"cell_type":"code","metadata":{"id":"CFXIgzNBEiuz"},"source":["# Create function to tokenize each article\n","def existing_tokens(sentence: str) -> list:\n","    \"\"\" Documentation \n","    Tokenize a sentence, and returns only the tokens existing in the vocabulary of the model\n","    Parameters:\n","        sentence: sentence to preprocess\n","    Out :\n","        list of words\n","    \"\"\"\n","\n","    # Keeps words or the article only if they are in the model vocabulary\n","    sentence = set(nltk.word_tokenize(str(sentence)))\n","    intersection = sentence.intersection(set(model.vocab.keys()))\n","    return list(intersection)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lUFwLtH5MISW"},"source":["# Apply the function existing_tokens to the column 'art_content_clean'\n","data['art_content_clean'] = data['art_content_clean'].apply(existing_tokens)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UwXSt3Bqun9P"},"source":["# save data on drive\n","#data.to_json(r'/content/drive/MyDrive/PIP 2021/Données/FastText/article_with_vocab_intersection.json', orient='records')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ll1zU5wp4psp"},"source":["## Import cleaned tokenized data"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":202},"id":"kYtclV4YwfLF","executionInfo":{"elapsed":1754,"status":"ok","timestamp":1610625818837,"user":{"displayName":"Ling","photoUrl":"","userId":"05619430897057846277"},"user_tz":-60},"outputId":"e5a30e72-9a80-4b5b-ea2c-2ebd7a973dc9"},"source":["data = pd.read_json(\n","   '/content/drive/MyDrive/PIP 2021/Données/FastText/article_with_vocab_intersection.json')\n","data.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>art_id</th>\n","      <th>art_content</th>\n","      <th>art_content_clean</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>La FNCDG et l’ANDCDG ont publié en septembre l...</td>\n","      <td>[panorama, collectivites, offerts, confrontes,...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>Malgré la levée des mesures de confinement le ...</td>\n","      <td>[prises, telecharger, levee, sante, reprise, c...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>25</td>\n","      <td>Quels étaient les objectifs poursuivis par le ...</td>\n","      <td>[directions, mutualisation, primaute, saisi, o...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>27</td>\n","      <td>La journée thématique, qui aura lieu durant le...</td>\n","      <td>[deroulera, colloque, innovantes, domaines, du...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>28</td>\n","      <td>La 1ère journée thématique en région sur le th...</td>\n","      <td>[communaute, deroulera, durant, publique, edit...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  art_id  ...                                  art_content_clean\n","0      1  ...  [panorama, collectivites, offerts, confrontes,...\n","1      2  ...  [prises, telecharger, levee, sante, reprise, c...\n","2     25  ...  [directions, mutualisation, primaute, saisi, o...\n","3     27  ...  [deroulera, colloque, innovantes, domaines, du...\n","4     28  ...  [communaute, deroulera, durant, publique, edit...\n","\n","[5 rows x 3 columns]"]},"metadata":{"tags":[]},"execution_count":25}]},{"cell_type":"code","metadata":{"id":"dV2KEHURbomf"},"source":["# Remove sentences that doesn't contain any word of the model vocabulary\n","data = data[data['art_content_clean'].apply(lambda x: len(x) != 0)]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4dUQ6P_ZKINg"},"source":["# Build sentences again from tokens\n","data['art_content_not_tokenized'] = [\n","    ' '.join(sentence) for sentence in data['art_content_clean']]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UljdhnWKiRCR"},"source":["data.head()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dLuM67eO9efa"},"source":["## TFIDF"]},{"cell_type":"markdown","metadata":{"id":"fTe9OynQ9efa"},"source":["We want to get the IDF of each word in the vocab in order to balance the word embedding values"]},{"cell_type":"code","metadata":{"id":"Q0DhtCu9cnPr"},"source":["# Calculation of the idf value of each word\n","vectorizer = TfidfVectorizer()\n","\n","# fit_transform needs non-tokenized sentences\n","x = vectorizer.fit_transform(data['art_content_not_tokenized'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ROk_nH6HcnPv"},"source":["# Dictionary containing the idf value of each word\n","# vectorizer.idf_ gives the idf value of each word\n","dic_weights = dict(zip(vectorizer.get_feature_names(), vectorizer.idf_))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cbA1M3eL9efc"},"source":["## Compute the embeddings of each sentence"]},{"cell_type":"code","metadata":{"id":"5M91lVRLcnPw"},"source":["# Create function to calculate mean vector for each article\n","# Output vector can be weighted (boolean set to True) or unweighted (boolean set to False)\n","def vect_mean(sentence: list, weighted: bool) -> list:\n","    \"\"\" Documentation \n","    Returns a list representing the average of the array's words' sentence \n","    weighted with it's idf value\n","    Out :\n","      list of 500 coordinates\n","    \"\"\"\n","\n","    if weighted:\n","        # Weight of each word\n","        if len(sentence) == 1:\n","            return model[sentence][0]\n","        else:\n","            poids = list(itemgetter(*sentence)(dic_weights))\n","            return np.average(model[sentence], axis=0, weights=poids)\n","    else:\n","        return np.mean(model[sentence], axis=0)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4faGm32AcnPz"},"source":["# Apply the function vect_mean with weights\n","data['vect_content_title_weighted'] = data.art_content_clean.apply(\n","    lambda x: vect_mean(x, True))\n","\n","# Apply the function vect_mean without weights\n","data['vect_content_title_unweighted'] = data.art_content_clean.apply(\n","    lambda x: vect_mean(x, False))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mHY9-C04ig09"},"source":["data.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":202},"id":"ik1F_PSzKINj","executionInfo":{"elapsed":594,"status":"ok","timestamp":1610626048181,"user":{"displayName":"Ling","photoUrl":"","userId":"05619430897057846277"},"user_tz":-60},"outputId":"21f6752e-9f4a-4f18-e699-6db7d143666a"},"source":["# Final DataFrame containing the 3 columns Id of the article (art_id) and intrinsic vector (vect_art) weighted and non weighted\n","final_data = data.drop(\n","    columns=['art_content', 'art_content_clean', 'art_content_not_tokenized'])\n","final_data.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>art_id</th>\n","      <th>vect_content_title_weighted</th>\n","      <th>vect_content_title_unweighted</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>[0.003699094353281652, 0.005638245658862409, 0...</td>\n","      <td>[0.0037260866, 0.005599999, 0.017443476, 0.000...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>[0.0022219835185113062, -0.0002882939163113805...</td>\n","      <td>[0.0015073532, 0.002485294, 0.0010749996, 0.00...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>25</td>\n","      <td>[6.080691828573314e-05, 0.015057803622787417, ...</td>\n","      <td>[-0.0013683748, 0.015395545, 0.00013407573, 0....</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>27</td>\n","      <td>[0.0015955066926961702, 0.01679796948292174, 0...</td>\n","      <td>[-0.00032615347, 0.02102154, 0.0033769228, 0.0...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>28</td>\n","      <td>[-0.0017359903365168625, 0.006722339617114802,...</td>\n","      <td>[-0.0016072913, 0.009063543, 0.0067187487, 0.0...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  art_id  ...                      vect_content_title_unweighted\n","0      1  ...  [0.0037260866, 0.005599999, 0.017443476, 0.000...\n","1      2  ...  [0.0015073532, 0.002485294, 0.0010749996, 0.00...\n","2     25  ...  [-0.0013683748, 0.015395545, 0.00013407573, 0....\n","3     27  ...  [-0.00032615347, 0.02102154, 0.0033769228, 0.0...\n","4     28  ...  [-0.0016072913, 0.009063543, 0.0067187487, 0.0...\n","\n","[5 rows x 3 columns]"]},"metadata":{"tags":[]},"execution_count":34}]},{"cell_type":"markdown","metadata":{"id":"nVe_zKqATLaY"},"source":["## Save dataframe of weighted vector of each article"]},{"cell_type":"code","metadata":{"id":"HfvP5f1EKINk"},"source":["# Exporting the final data\n","#final_data.to_json(r'/content/drive/MyDrive/PIP 2021/Données/FastText/article_embeddings.json', orient='records')"],"execution_count":null,"outputs":[]}]}